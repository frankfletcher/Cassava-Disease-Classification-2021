{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "unavailable-boards",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-02-25T07:12:49.132965Z",
     "iopub.status.busy": "2021-02-25T07:12:49.132857Z",
     "iopub.status.idle": "2021-02-25T07:12:49.136209Z",
     "shell.execute_reply": "2021-02-25T07:12:49.135626Z",
     "shell.execute_reply.started": "2021-02-25T07:12:49.132953Z"
    }
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../utils')\n",
    "\n",
    "from fastai.vision.all import *\n",
    "from fastai.vision.widgets import *\n",
    "import fastai\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import accuracy_score\n",
    "from augmentation import *\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "operational-island",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-02-25T07:12:49.137402Z",
     "iopub.status.busy": "2021-02-25T07:12:49.137259Z",
     "iopub.status.idle": "2021-02-25T07:12:49.140153Z",
     "shell.execute_reply": "2021-02-25T07:12:49.139677Z",
     "shell.execute_reply.started": "2021-02-25T07:12:49.137387Z"
    }
   },
   "outputs": [],
   "source": [
    "# RUN_NAME_OF_MODEL_TO_LOAD = '20210210-1221 - arch=tf_efficientnet_b4_ns - samples=1800 frozen=1 epochs=40 bs=8 res=480'  # BEST 87%\n",
    "# EPOCH_TO_LOAD=2\n",
    "\n",
    "# RUN_NAME_OF_MODEL_TO_LOAD = '20210209-0234 - arch=tf_efficientnet_b4_ns - samples=1800 frozen=1 epochs=40 bs=7 res=456'  # 83%\n",
    "# RUN_NAME_OF_MODEL_TO_LOAD = '20210214-1340 - arch=<function xse_resnext34 at 0x7fed41524d30> - samples=1800 frozen=1 epochs=60 bs=14 res=420'\n",
    "# EPOCH_TO_LOAD=15\n",
    "\n",
    "#f'20210209-0234 - arch=tf_efficientnet_b4_ns - samples=1800 frozen=1 epochs=40 bs=7 res=456'\n",
    "# EPOCH_TO_LOAD = 2\n",
    "\n",
    "# EPOCH_TO_LOAD = 8\n",
    "RUN_NAME_OF_MODEL_TO_LOAD = '20210215-0355 - arch=<function xse_resnext34 at 0x7f6ed4c51d30> - samples=1800 frozen=1 epochs=60 bs=32 res=250'\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# RESOLUTION = round(380 * 1.2)  # 300\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "RESOLUTION=700\n",
    "BATCH_SIZE = 10\n",
    "SAMPLE_SIZE = 2000\n",
    "\n",
    "path = '../../data'\n",
    "sub = 'train_images'  # 'test_images'\n",
    "# dataset_path = Path(path)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "hindu-chemistry",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-02-18T07:27:11.848236Z",
     "iopub.status.busy": "2021-02-18T07:27:11.848071Z",
     "iopub.status.idle": "2021-02-18T07:27:11.855873Z",
     "shell.execute_reply": "2021-02-18T07:27:11.855466Z",
     "shell.execute_reply.started": "2021-02-18T07:27:11.848220Z"
    },
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "source": [
    "from timm import create_model\n",
    "from fastai.vision.learner import _update_first_layer\n",
    "\n",
    "def create_timm_body(arch:str, pretrained=True, cut=None, n_in=3):\n",
    "    \"Creates a body from any model in the `timm` library.\"\n",
    "    model = create_model(arch, pretrained=pretrained, num_classes=0, global_pool='')\n",
    "    _update_first_layer(model, n_in, pretrained)\n",
    "    if cut is None:\n",
    "        ll = list(enumerate(model.children()))\n",
    "        cut = next(i for i,o in reversed(ll) if has_pool_type(o))\n",
    "    if isinstance(cut, int): return nn.Sequential(*list(model.children())[:cut])\n",
    "    elif callable(cut): return cut(model)\n",
    "    else: raise NamedError(\"cut must be either integer or function\")\n",
    "        \n",
    "def create_timm_model(arch:str, n_out, cut=None, pretrained=True, n_in=3, init=nn.init.kaiming_normal_, custom_head=None,\n",
    "                     concat_pool=False, **kwargs):\n",
    "    \"Create custom architecture using `arch`, `n_in` and `n_out` from the `timm` library\"\n",
    "    body = create_timm_body(arch, pretrained, None, n_in)\n",
    "    if custom_head is None:\n",
    "        nf = num_features_model(nn.Sequential(*body.children())) * (2 if concat_pool else 1)\n",
    "        head = create_head(nf, n_out, concat_pool=concat_pool, **kwargs)\n",
    "    else: head = custom_head\n",
    "    model = nn.Sequential(body, head)\n",
    "    if init is not None: apply_init(model[1], init)\n",
    "    return model\n",
    "\n",
    "\n",
    "def timm_learner(dls, arch:str, loss_func=None, pretrained=True, cut=None, splitter=None,\n",
    "                y_range=None, config=None, n_out=None, normalize=True, **kwargs):\n",
    "    \"Build a convnet style learner from `dls` and `arch` using the `timm` library\"\n",
    "    if config is None: config = {}\n",
    "    if n_out is None: n_out = get_c(dls)\n",
    "    assert n_out, \"`n_out` is not defined, and could not be inferred from data, set `dls.c` or pass `n_out`\"\n",
    "    if y_range is None and 'y_range' in config: y_range = config.pop('y_range')\n",
    "    model = create_timm_model(arch, n_out, default_split, pretrained, y_range=y_range, **config)\n",
    "    learn = Learner(dls, model, loss_func=loss_func, splitter=default_split, **kwargs)\n",
    "    if pretrained: learn.freeze()\n",
    "    return learn"
   ]
  },
  {
   "cell_type": "raw",
   "id": "forty-cooling",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-02-18T07:27:11.856588Z",
     "iopub.status.busy": "2021-02-18T07:27:11.856435Z",
     "iopub.status.idle": "2021-02-18T07:27:11.860006Z",
     "shell.execute_reply": "2021-02-18T07:27:11.859657Z",
     "shell.execute_reply.started": "2021-02-18T07:27:11.856572Z"
    },
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "source": [
    "class MishAutoFn(torch.autograd.Function):\n",
    "    \"\"\"Mish: A Self Regularized Non-Monotonic Neural Activation Function - https://arxiv.org/abs/1908.08681\n",
    "    Experimental memory-efficient variant\n",
    "    \"\"\"\n",
    "\n",
    "    @staticmethod\n",
    "    def forward(ctx, x):\n",
    "        ctx.save_for_backward(x)\n",
    "        y = x.mul(torch.tanh(F.softplus(x)))  # x * tanh(ln(1 + exp(x)))\n",
    "       return y\n",
    "\n",
    "    @staticmethod\n",
    "    def backward(ctx, grad_output):\n",
    "        x = ctx.saved_tensors[0]\n",
    "        x_sigmoid = torch.sigmoid(x)\n",
    "        x_tanh_sp = F.softplus(x).tanh()\n",
    "        return grad_output.mul(x_tanh_sp + x * x_sigmoid * (1 - x_tanh_sp * x_tanh_sp))\n",
    "\n",
    "\n",
    "def mish_auto(x, inplace=False):\n",
    "    # inplace ignored\n",
    "    return MishAutoFn.apply(x)\n",
    "\n",
    "\n",
    "class MishAuto(nn.Module):\n",
    "    def __init__(self, inplace: bool = True):\n",
    "        super(MishAuto, self).__init__()\n",
    "        self.inplace = inplace\n",
    "\n",
    "    def forward(self, x):\n",
    "        return MishAutoFn.apply(x)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "competitive-bangkok",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-02-18T07:27:11.860501Z",
     "iopub.status.busy": "2021-02-18T07:27:11.860403Z",
     "iopub.status.idle": "2021-02-18T07:27:11.864729Z",
     "shell.execute_reply": "2021-02-18T07:27:11.864459Z",
     "shell.execute_reply.started": "2021-02-18T07:27:11.860491Z"
    },
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "source": [
    "import albumentations\n",
    "\n",
    "class AlbumentationsTransform(RandTransform):\n",
    "    \"A transform handler for multiple `Albumentation` transforms\"\n",
    "    split_idx,order=None,2\n",
    "    def __init__(self, train_aug, valid_aug): store_attr()\n",
    "    \n",
    "    def before_call(self, b, split_idx):\n",
    "        self.idx = split_idx\n",
    "    \n",
    "    def encodes(self, img: PILImage):\n",
    "        if self.idx == 0:\n",
    "            aug_img = self.train_aug(image=np.array(img))['image']\n",
    "        else:\n",
    "            aug_img = self.valid_aug(image=np.array(img))['image']\n",
    "        return PILImage.create(aug_img)\n",
    "    \n",
    "    \n",
    "def get_train_aug(): return albumentations.Compose([\n",
    "            albumentations.RandomResizedCrop(256,256),\n",
    "            albumentations.Transpose(p=0.5),\n",
    "            albumentations.HorizontalFlip(p=0.5),\n",
    "            albumentations.VerticalFlip(p=0.5),\n",
    "            albumentations.ShiftScaleRotate(p=0.5),\n",
    "            albumentations.HueSaturationValue(\n",
    "                hue_shift_limit=0.2, \n",
    "                sat_shift_limit=0.2, \n",
    "                val_shift_limit=0.2, \n",
    "                p=0.5\n",
    "            ),\n",
    "            albumentations.RandomBrightnessContrast(\n",
    "                brightness_limit=(-0.1,0.1), \n",
    "                contrast_limit=(-0.1, 0.1), \n",
    "                p=0.5\n",
    "            ),\n",
    "            albumentations.CoarseDropout(p=0.5),\n",
    "            albumentations.Cutout(p=0.5)\n",
    "])\n",
    "\n",
    "\n",
    "\n",
    "def get_valid_aug(): return albumentations.Compose([\n",
    "    albumentations.CenterCrop(256,256, p=1.),\n",
    "    albumentations.Resize(256,256)\n",
    "], p=1.)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "relative-dublin",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-02-25T07:12:49.141071Z",
     "iopub.status.busy": "2021-02-25T07:12:49.140931Z",
     "iopub.status.idle": "2021-02-25T07:12:49.148694Z",
     "shell.execute_reply": "2021-02-25T07:12:49.148276Z",
     "shell.execute_reply.started": "2021-02-25T07:12:49.141056Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_id</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1071960213.jpg</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>train-cbb-29.jpg</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>train-cbb-284.jpg</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>train-cbb-151.jpg</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>249609077.jpg</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            image_id  label\n",
       "0     1071960213.jpg      0\n",
       "1   train-cbb-29.jpg      0\n",
       "2  train-cbb-284.jpg      0\n",
       "3  train-cbb-151.jpg      0\n",
       "4      249609077.jpg      0"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# sample_df = pd.read_csv(f'{path}/sample_submission.csv')\n",
    "sample_df = pd.read_csv(f'{path}/all_test_files.csv')\n",
    "# sample_df = sample_df.head(50)\n",
    "sample_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "pretty-nylon",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-02-25T07:12:49.149266Z",
     "iopub.status.busy": "2021-02-25T07:12:49.149164Z",
     "iopub.status.idle": "2021-02-25T07:12:49.150748Z",
     "shell.execute_reply": "2021-02-25T07:12:49.150455Z",
     "shell.execute_reply.started": "2021-02-25T07:12:49.149255Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "## sample_df['image_id'] =  f'{path}/' + sample_df['image_id'].astype(str)\n",
    "# cols = sample_df.columns.tolist()\n",
    "# cols = cols[::-1]\n",
    "# sample_df = sample_df[cols]\n",
    "##sample_df[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "fossil-moscow",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-02-25T07:13:20.543019Z",
     "iopub.status.busy": "2021-02-25T07:13:20.542896Z",
     "iopub.status.idle": "2021-02-25T07:13:20.550779Z",
     "shell.execute_reply": "2021-02-25T07:13:20.550455Z",
     "shell.execute_reply.started": "2021-02-25T07:13:20.543006Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_id</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1071960213.jpg</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>train-cbb-29.jpg</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>train-cbb-284.jpg</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>train-cbb-151.jpg</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>249609077.jpg</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2700</th>\n",
       "      <td>2609756462.jpg</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2701</th>\n",
       "      <td>2654037367.jpg</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2702</th>\n",
       "      <td>3757297104.jpg</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2703</th>\n",
       "      <td>train-healthy-69.jpg</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2704</th>\n",
       "      <td>2893323611.jpg</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2705 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                  image_id  label\n",
       "0           1071960213.jpg      0\n",
       "1         train-cbb-29.jpg      0\n",
       "2        train-cbb-284.jpg      0\n",
       "3        train-cbb-151.jpg      0\n",
       "4            249609077.jpg      0\n",
       "...                    ...    ...\n",
       "2700        2609756462.jpg      4\n",
       "2701        2654037367.jpg      4\n",
       "2702        3757297104.jpg      4\n",
       "2703  train-healthy-69.jpg      4\n",
       "2704        2893323611.jpg      4\n",
       "\n",
       "[2705 rows x 2 columns]"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s = sample_df.image_id.str.split('/')\n",
    "s = pd.Series([line[-1] for line in s], name='image_id')\n",
    "sample_df.loc[:, 'image_id'] = s\n",
    "sample_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "interested-daisy",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-02-25T07:13:27.244485Z",
     "iopub.status.busy": "2021-02-25T07:13:27.244221Z",
     "iopub.status.idle": "2021-02-25T07:13:27.251150Z",
     "shell.execute_reply": "2021-02-25T07:13:27.250524Z",
     "shell.execute_reply.started": "2021-02-25T07:13:27.244462Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_id</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1071960213.jpg</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>train-cbb-29.jpg</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>train-cbb-284.jpg</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>train-cbb-151.jpg</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>249609077.jpg</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            image_id  label\n",
       "0     1071960213.jpg      0\n",
       "1   train-cbb-29.jpg      0\n",
       "2  train-cbb-284.jpg      0\n",
       "3  train-cbb-151.jpg      0\n",
       "4      249609077.jpg      0"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "wireless-liberia",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-02-25T07:01:46.866052Z",
     "iopub.status.busy": "2021-02-25T07:01:46.865783Z",
     "iopub.status.idle": "2021-02-25T07:01:46.868508Z",
     "shell.execute_reply": "2021-02-25T07:01:46.867988Z",
     "shell.execute_reply.started": "2021-02-25T07:01:46.866028Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# sample_df = sample_df.sample(n=SAMPLE_SIZE, replace=False)  # random sample"
   ]
  },
  {
   "cell_type": "raw",
   "id": "radical-undergraduate",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-02-10T10:43:52.972222Z",
     "iopub.status.busy": "2021-02-10T10:43:52.971923Z",
     "iopub.status.idle": "2021-02-10T10:43:53.020481Z",
     "shell.execute_reply": "2021-02-10T10:43:53.020073Z",
     "shell.execute_reply.started": "2021-02-10T10:43:52.972192Z"
    },
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "source": [
    "\n",
    "\n",
    "def get_fnames(path):\n",
    "\n",
    "    retlist = list(sample_df['image_id'])\n",
    "            \n",
    "    return random.sample(retlist, len(retlist))\n",
    "\n",
    "aug_tfms =  aug_transforms(size=round(RESOLUTION * 1), pad_mode='zeros', do_flip=True, batch=False, \n",
    "                               p_affine=0.4, max_rotate=20, max_warp=0, min_zoom=1.0, max_zoom=1.0, \n",
    "                               mult=3.8,  p_lighting=0., max_lighting=0.1)\n",
    "\n",
    "sat = Saturation(p=0.7, max_lighting=0.15)\n",
    "\n",
    "# batch_tfms = [ Normalize.from_stats(*imagenet_stats), sat]\n",
    "batch_tfms = [ *aug_tfms, sat, Normalize.from_stats(*imagenet_stats) ]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# item_tfms=RandomResizedCrop(RESOLUTION)\n",
    "item_tfms=Resize(RESOLUTION, method='bilinear', pad_mode='zeros')\n",
    "# item_tfms=RatioResize(RESOLUTION)\n",
    "\n",
    "\n",
    "# img_db = DataBlock(\n",
    "#     blocks=(ImageBlock, CategoryBlock), \n",
    "#     get_items=get_fnames, \n",
    "#     splitter=RandomSplitter(valid_pct=0.28, seed=42),\n",
    "#     get_y=parent_label,\n",
    "#     item_tfms=item_tfms , batch_tfms=batch_tfms)\n",
    "\n",
    "# dls = img_db.dataloaders(dataset_path, batch_size=BATCH_SIZE)\n",
    "dls = ImageDataLoaders.from_df(sample_df, folder=f'../data/{sub}', seed=42, label_col = 0, fn_col=1, \n",
    "                               batch_tfms=batch_tfms, bs=BATCH_SIZE, item_tfms=item_tfms)\n",
    "test_dl = dls.test_dl(sample_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "exact-holocaust",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-02-25T07:13:29.847915Z",
     "iopub.status.busy": "2021-02-25T07:13:29.847660Z",
     "iopub.status.idle": "2021-02-25T07:13:30.040050Z",
     "shell.execute_reply": "2021-02-25T07:13:30.039696Z",
     "shell.execute_reply.started": "2021-02-25T07:13:29.847893Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# aug_tfms =  aug_transforms(size=RESOLUTION, pad_mode='reflection', do_flip=True, batch=False, \n",
    "#                                p_affine=0.7, max_rotate=45, max_warp=0, min_zoom=1.0, max_zoom=2.5, \n",
    "#                                mult=3,  p_lighting=0.5, max_lighting=0.1, min_scale=0.75) #,xtra_tfms=[sha])\n",
    "\n",
    "sat = Saturation(p=0.7, max_lighting=0.2)\n",
    "\n",
    "# batch_tfms = [ Normalize.from_stats(*imagenet_stats), sat]\n",
    "# batch_tfms = [ *aug_tfms, sat, Normalize.from_stats(*imagenet_stats)]#, sha]\n",
    "batch_tfms = [ Normalize.from_stats(*imagenet_stats) ]#, sha]\n",
    "\n",
    "# item_tfms=RandomResizedCrop(RESOLUTION)\n",
    "item_tfms = AlbumentationsTransform(get_train_aug(RESOLUTION), get_valid_aug(RESOLUTION))\n",
    "\n",
    "# item_tfms=Resize(RESOLUTION, method='bilinear', pad_mode='zeros')\n",
    "#     item_tfms=RatioResize(RESOLUTION)\n",
    "\n",
    "dls = ImageDataLoaders.from_df(sample_df, folder=f'../../data/{sub}', seed=42, label_col=1, fn_col=0, \n",
    "                               batch_tfms=batch_tfms, bs=BATCH_SIZE, item_tfms=item_tfms)\n",
    "test_dl = dls.test_dl(sample_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "living-elimination",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-02-25T07:13:32.469574Z",
     "iopub.status.busy": "2021-02-25T07:13:32.469322Z",
     "iopub.status.idle": "2021-02-25T07:13:32.473234Z",
     "shell.execute_reply": "2021-02-25T07:13:32.472685Z",
     "shell.execute_reply.started": "2021-02-25T07:13:32.469551Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method DataLoaders.test_dl of <fastai.data.core.DataLoaders object at 0x7f35decb33a0>>"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dls.test_dl"
   ]
  },
  {
   "cell_type": "raw",
   "id": "desirable-while",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-02-11T00:06:57.986535Z",
     "iopub.status.busy": "2021-02-11T00:06:57.986277Z",
     "iopub.status.idle": "2021-02-11T00:06:57.995725Z",
     "shell.execute_reply": "2021-02-11T00:06:57.995113Z",
     "shell.execute_reply.started": "2021-02-11T00:06:57.986512Z"
    },
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "source": [
    "# General use - if the model was pickled\n",
    "model = load_learner(f'../models/{RUN_NAME_OF_MODEL_TO_LOAD}.pkl', cpu=False)\n",
    "load_model(f'models/{RUN_NAME_OF_MODEL_TO_LOAD}_{EPOCH_TO_LOAD}.pth', model, opt=Adam, with_opt=False)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "civic-interstate",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-02-18T07:27:13.226719Z",
     "iopub.status.busy": "2021-02-18T07:27:13.226603Z",
     "iopub.status.idle": "2021-02-18T07:27:13.233999Z",
     "shell.execute_reply": "2021-02-18T07:27:13.233489Z",
     "shell.execute_reply.started": "2021-02-18T07:27:13.226707Z"
    },
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "source": [
    "import kornia\n",
    "def convert_MP_to_blurMP(model, layer_type_old):\n",
    "    conversion_count = 0\n",
    "    for name, module in reversed(model._modules.items()):\n",
    "        if len(list(module.children())) > 0:\n",
    "            # recurse\n",
    "            model._modules[name] = convert_MP_to_blurMP(module, layer_type_old)\n",
    "\n",
    "        if type(module) == layer_type_old:\n",
    "            layer_old = module\n",
    "            layer_new = kornia.contrib.MaxBlurPool2d(3, True)\n",
    "            model._modules[name] = layer_new\n",
    "\n",
    "    return model\n",
    "\n",
    "\n",
    "def convert_act_cls(model, layer_type_old, layer_type_new):\n",
    "    conversion_count = 0\n",
    "    for name, module in reversed(model._modules.items()):\n",
    "        if len(list(module.children())) > 0:\n",
    "            # recurse\n",
    "            model._modules[name] = convert_act_cls(module, layer_type_old, layer_type_new)\n",
    "\n",
    "        if type(module) == layer_type_old:\n",
    "            layer_old = module\n",
    "            layer_new = layer_type_new\n",
    "            model._modules[name] = layer_new\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "raw",
   "id": "filled-wisdom",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-02-18T07:27:13.235236Z",
     "iopub.status.busy": "2021-02-18T07:27:13.234948Z",
     "iopub.status.idle": "2021-02-18T07:27:13.243909Z",
     "shell.execute_reply": "2021-02-18T07:27:13.243636Z",
     "shell.execute_reply.started": "2021-02-18T07:27:13.235208Z"
    },
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "source": [
    "class SwishAutoFn(torch.autograd.Function):\n",
    "    \"\"\"Swish - Described in: https://arxiv.org/abs/1710.05941\n",
    "    Memory efficient variant from:\n",
    "     https://medium.com/the-artificial-impostor/more-memory-efficient-swish-activation-function-e07c22c12a76\n",
    "    \"\"\"\n",
    "    @staticmethod\n",
    "    def forward(ctx, x):\n",
    "        result = x.mul(torch.sigmoid(x))\n",
    "        ctx.save_for_backward(x)\n",
    "        return result\n",
    "\n",
    "    @staticmethod\n",
    "    def backward(ctx, grad_output):\n",
    "        x = ctx.saved_tensors[0]\n",
    "        x_sigmoid = torch.sigmoid(x)\n",
    "        return grad_output.mul(x_sigmoid * (1 + x * (1 - x_sigmoid)))\n",
    "\n",
    "\n",
    "def swish_auto(x, inplace=False):\n",
    "    # inplace ignored\n",
    "    return SwishAutoFn.apply(x)\n",
    "\n",
    "\n",
    "class SwishAuto(nn.Module):\n",
    "    def __init__(self, inplace: bool = True):\n",
    "        super(SwishAuto, self).__init__()\n",
    "        self.inplace = inplace\n",
    "\n",
    "    def forward(self, x):\n",
    "        return SwishAutoFn.apply(x)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "class MishAutoFn(torch.autograd.Function):\n",
    "    \"\"\"Mish: A Self Regularized Non-Monotonic Neural Activation Function - https://arxiv.org/abs/1908.08681\n",
    "    Experimental memory-efficient variant\n",
    "    \"\"\"\n",
    "\n",
    "    @staticmethod\n",
    "    def forward(ctx, x):\n",
    "        ctx.save_for_backward(x)\n",
    "        y = x.mul(torch.tanh(F.softplus(x)))  # x * tanh(ln(1 + exp(x)))\n",
    "        return y\n",
    "\n",
    "    @staticmethod\n",
    "    def backward(ctx, grad_output):\n",
    "        x = ctx.saved_tensors[0]\n",
    "        x_sigmoid = torch.sigmoid(x)\n",
    "        x_tanh_sp = F.softplus(x).tanh()\n",
    "        return grad_output.mul(x_tanh_sp + x * x_sigmoid * (1 - x_tanh_sp * x_tanh_sp))\n",
    "\n",
    "\n",
    "def mish_auto(x, inplace=False):\n",
    "    # inplace ignored\n",
    "    return MishAutoFn.apply(x)\n",
    "\n",
    "\n",
    "class MishAuto(nn.Module):\n",
    "    def __init__(self, inplace: bool = True):\n",
    "        super(MishAuto, self).__init__()\n",
    "        self.inplace = inplace\n",
    "\n",
    "    def forward(self, x):\n",
    "        return MishAutoFn.apply(x)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "delayed-dinner",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-02-18T07:27:13.244403Z",
     "iopub.status.busy": "2021-02-18T07:27:13.244302Z",
     "iopub.status.idle": "2021-02-18T07:27:13.248507Z",
     "shell.execute_reply": "2021-02-18T07:27:13.248241Z",
     "shell.execute_reply.started": "2021-02-18T07:27:13.244392Z"
    },
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "source": [
    "\n",
    "\n",
    "from torch.utils.checkpoint import checkpoint, checkpoint_sequential\n",
    "\n",
    "class CheckpointModule(Module):\n",
    "    def __init__(self, module, num_segments=1):\n",
    "        assert num_segments == 1 or isinstance(module, nn.Sequential)\n",
    "        self.module = module\n",
    "        self.num_segments = num_segments\n",
    "\n",
    "    def forward(self, *inputs):\n",
    "        if self.num_segments > 1:\n",
    "            return checkpoint_sequential(self.module, self.num_segments, *inputs)\n",
    "        else:\n",
    "            return checkpoint(self.module, *inputs)\n",
    "        \n",
    "        \n",
    "\n",
    "# To extract the sequential layers from resnet\n",
    "def layer_config(arch):\n",
    "    \"Get the layers associated with `arch`.\"\n",
    "    return model_layers.get(arch)\n",
    "\n",
    "\n",
    "model_layers = {\n",
    "    resnet18 :[2, 2, 2, 2], resnet34: [3, 4, 6, 3],\n",
    "    resnet50 :[3, 4, 6, 3], resnet101:[3, 4, 23, 3],\n",
    "    resnet152:[3, 8, 36, 3]}\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "def convert_seq_chkpt(model, layer_type_old):  #, num_chkpt):\n",
    "#     seg_dict = {2:2, 3:6, 4:5, 5:5, 6:3, 7:3, 8:2, 1:1}\n",
    "    conversion_count = 0\n",
    "    for name, module in reversed(model._modules.items()):\n",
    "        if len(list(module.children())) > 0:\n",
    "            # recurse\n",
    "            model._modules[name] = convert_seq_chkpt(module, layer_type_old) #, num_chkpt+1)\n",
    "\n",
    "        if type(module) == layer_type_old:\n",
    "#             num_chkpt += 1\n",
    "            layer_old = module\n",
    "            if len(layer_old) == 7:\n",
    "                segments = 1\n",
    "            else: segments = len(layer_old)\n",
    "            layer_new = CheckpointModule(layer_old, segments)  # wrap sequential in a checkpoint module\n",
    "            model._modules[name] = layer_new\n",
    "#             print(num_chkpt)  # 2,3,4,5,6,7,8,1\n",
    "#             print(len(layer_old))\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "unknown-briefing",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-02-25T07:13:42.217785Z",
     "iopub.status.busy": "2021-02-25T07:13:42.217580Z",
     "iopub.status.idle": "2021-02-25T07:13:42.239578Z",
     "shell.execute_reply": "2021-02-25T07:13:42.238494Z",
     "shell.execute_reply.started": "2021-02-25T07:13:42.217768Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Attempting to deserialize object on a CUDA device but torch.cuda.is_available() is False. If you are running on a CPU-only machine, please use torch.load with map_location=torch.device('cpu') to map your storages to the CPU.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-67-45008887599f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mload_learner\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'../DenseNet/models/STAGE1_20210223-0550 - arch=densenetblur121d - samples=-1 frozen=1 epochs=5 bs=32 res=300.pkl'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcpu\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/learn/lib/python3.8/site-packages/fastai/learner.py\u001b[0m in \u001b[0;36mload_learner\u001b[0;34m(fname, cpu, pickle_module)\u001b[0m\n\u001b[1;32m    372\u001b[0m     \u001b[0;34m\"Load a `Learner` object in `fname`, optionally putting it on the `cpu`\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    373\u001b[0m     \u001b[0mdistrib_barrier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 374\u001b[0;31m     \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmap_location\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'cpu'\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mcpu\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpickle_module\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpickle_module\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    375\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mres\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'to_fp32'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mres\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_fp32\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    376\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcpu\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mres\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/learn/lib/python3.8/site-packages/torch/serialization.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(f, map_location, pickle_module, **pickle_load_args)\u001b[0m\n\u001b[1;32m    592\u001b[0m                     \u001b[0mopened_file\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mseek\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0morig_position\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    593\u001b[0m                     \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjit\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopened_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 594\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0m_load\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopened_zipfile\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmap_location\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpickle_module\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mpickle_load_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    595\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0m_legacy_load\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopened_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmap_location\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpickle_module\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mpickle_load_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    596\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/learn/lib/python3.8/site-packages/torch/serialization.py\u001b[0m in \u001b[0;36m_load\u001b[0;34m(zip_file, map_location, pickle_module, pickle_file, **pickle_load_args)\u001b[0m\n\u001b[1;32m    851\u001b[0m     \u001b[0munpickler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpickle_module\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mUnpickler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mpickle_load_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    852\u001b[0m     \u001b[0munpickler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpersistent_load\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpersistent_load\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 853\u001b[0;31m     \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0munpickler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    854\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    855\u001b[0m     \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_loaded_sparse_tensors\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/learn/lib/python3.8/site-packages/torch/serialization.py\u001b[0m in \u001b[0;36mpersistent_load\u001b[0;34m(saved_id)\u001b[0m\n\u001b[1;32m    843\u001b[0m         \u001b[0mdata_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlocation\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msize\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    844\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mkey\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mloaded_storages\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 845\u001b[0;31m             \u001b[0mload_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msize\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_maybe_decode_ascii\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlocation\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    846\u001b[0m         \u001b[0mstorage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloaded_storages\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    847\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mstorage\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/learn/lib/python3.8/site-packages/torch/serialization.py\u001b[0m in \u001b[0;36mload_tensor\u001b[0;34m(data_type, size, key, location)\u001b[0m\n\u001b[1;32m    832\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    833\u001b[0m         \u001b[0mstorage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mzip_file\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_storage_from_record\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msize\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstorage\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 834\u001b[0;31m         \u001b[0mloaded_storages\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrestore_location\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstorage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlocation\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    835\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    836\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mpersistent_load\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msaved_id\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/learn/lib/python3.8/site-packages/torch/serialization.py\u001b[0m in \u001b[0;36mdefault_restore_location\u001b[0;34m(storage, location)\u001b[0m\n\u001b[1;32m    173\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mdefault_restore_location\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstorage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlocation\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    174\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m \u001b[0;32min\u001b[0m \u001b[0m_package_registry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 175\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstorage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlocation\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    176\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mresult\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    177\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/learn/lib/python3.8/site-packages/torch/serialization.py\u001b[0m in \u001b[0;36m_cuda_deserialize\u001b[0;34m(obj, location)\u001b[0m\n\u001b[1;32m    149\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_cuda_deserialize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlocation\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    150\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlocation\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstartswith\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'cuda'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 151\u001b[0;31m         \u001b[0mdevice\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalidate_cuda_device\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlocation\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    152\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"_torch_load_uninitialized\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    153\u001b[0m             \u001b[0mstorage_type\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/learn/lib/python3.8/site-packages/torch/serialization.py\u001b[0m in \u001b[0;36mvalidate_cuda_device\u001b[0;34m(location)\u001b[0m\n\u001b[1;32m    133\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    134\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_available\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 135\u001b[0;31m         raise RuntimeError('Attempting to deserialize object on a CUDA '\n\u001b[0m\u001b[1;32m    136\u001b[0m                            \u001b[0;34m'device but torch.cuda.is_available() is False. '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    137\u001b[0m                            \u001b[0;34m'If you are running on a CPU-only machine, '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Attempting to deserialize object on a CUDA device but torch.cuda.is_available() is False. If you are running on a CPU-only machine, please use torch.load with map_location=torch.device('cpu') to map your storages to the CPU."
     ]
    }
   ],
   "source": [
    "# model = load_learner(f'../models/{RUN_NAME_OF_MODEL_TO_LOAD}.pkl', cpu=False)\n",
    "# import timm\n",
    "# model = timm_learner(dls,\n",
    "#                     'tf_efficientnet_b4_ns',\n",
    "#                      opt_func=ranger,\n",
    "#                      loss_func=LabelSmoothingCrossEntropy(),\n",
    "#           #           cbs=cbs,\n",
    "#                      metrics = [accuracy]).to_fp16()\n",
    "\n",
    "\n",
    "# ARCH = xse_resnext34(pretrained=True, act_cls=MishAuto, sa=True)\n",
    "\n",
    "# model = Learner(dls, ARCH, \n",
    "#                     opt_func=ranger,\n",
    "#                     loss_func=LabelSmoothingCrossEntropyFlat(), \n",
    "#                      metrics=[accuracy])\n",
    "\n",
    "\n",
    "model=load_learner('../DenseNet/models/STAGE1_20210223-0550 - arch=densenetblur121d - samples=-1 frozen=1 epochs=5 bs=32 res=300.pkl', cpu=False)\n",
    "\n",
    "\n",
    "# model = convert_MP_to_blurMP(model, nn.MaxPool2d)  # doesn't exist!\n",
    "# model.model = convert_act_cls(model.model, nn.ReLU, MishAuto())  # very expensive so we only use it on the last layers\n",
    "# model.model = convert_act_cls(model.model, nn.SiLU, SwishAuto())  # replace with a lower memory version\n",
    "# model.model[0] = convert_seq_chkpt(model.model[0], nn.Sequential) #, 0)  # wrap all BODY sequentials to use Gradient Checkpointing\n",
    "# model.model[0] = nn.Sequential(CheckpointModule(model.model[0]))  # hack in the final checkpointmodule for the base sequence\n",
    "\n",
    "# @TODO WATCHT HIS\n",
    "# model = model.to_fp16()  # convert to 16bit\n",
    "\n",
    "# load_model(f'models/{RUN_NAME_OF_MODEL_TO_LOAD}_{EPOCH_TO_LOAD}.pth', model, opt=ranger, with_opt=False)\n",
    "\n",
    "# model = model.to_fp32()\n",
    "\n",
    "\n",
    "load_model('../DenseNet/models/20210223-0550 - arch=densenetblur121d - samples=-1 frozen=1 epochs=5 bs=32 res=300_split_8_epoch25_acc0.88.pth', model, opt=ranger)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "macro-plaintiff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# preds, something = model.tta(dl=test_dl, n=5, use_max=False, beta=0.18)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "czech-backing",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_dl.show_batch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "departmental-business",
   "metadata": {},
   "outputs": [],
   "source": [
    "preds, something = model.tta(dl=test_dl, n=5)  #, use_max=False, beta=0.1)\n",
    "print(classification_report(sample_df.iloc[:,0], preds.argmax(dim=-1).numpy()))  # TTA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "weekly-heart",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "preds2 = model.get_preds(dl=test_dl)\n",
    "print(classification_report(sample_df.iloc[:,0], preds2[0].argmax(dim=-1).numpy()))  # straight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "beginning-vulnerability",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(classification_report(sample_df.iloc[:,0], ((preds + preds2[0]).argmax(dim=-1).numpy())))  # average"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "particular-loading",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(classification_report(sample_df.iloc[:,0], (torch.maximum(preds,preds2[0]).argmax(dim=-1).numpy())))  # max"
   ]
  },
  {
   "cell_type": "raw",
   "id": "hairy-boundary",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-02-10T05:16:58.253381Z",
     "iopub.status.busy": "2021-02-10T05:16:58.253114Z",
     "iopub.status.idle": "2021-02-10T05:24:35.347008Z",
     "shell.execute_reply": "2021-02-10T05:24:35.346391Z",
     "shell.execute_reply.started": "2021-02-10T05:16:58.253359Z"
    }
   },
   "source": [
    "scores_gs = []\n",
    "nlist = [5,10,15,20,30,40]\n",
    "\n",
    "for i in nlist:\n",
    "    preds_gs, _ = model.tta(dl=test_dl, n=i)  #, use_max=False, beta=0.1)\n",
    "    scores_gs.append(accuracy_score(sample_df.iloc[:,0], preds.argmax(dim=-1).numpy()))\n",
    "    \n",
    "print(f'best n: {nlist[np.argmax(scores_gs)]}')\n",
    "print(scores_gs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "proved-phrase",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import albumentations as A\n",
    "\n",
    "\n",
    "# class AlbumentationsTransform(DisplayedTransform):\n",
    "#     split_idx,order=0,2\n",
    "#     def __init__(self, train_aug): store_attr()\n",
    "    \n",
    "#     def encodes(self, img: PILImage):\n",
    "#         aug_img = self.train_aug(image=np.array(img))['image']\n",
    "#         return PILImage.create(aug_img)\n",
    "    \n",
    "# # get_t_tfms():\n",
    "# #     return A.Compose()\n",
    "\n",
    "\n",
    "# aug = A.Sharpen(p=1, alpha=(0.99,1), lightness=(0.5,0.5))\n",
    "# sha = AlbumentationsTransform(aug)\n",
    "# def aug_tfm(img): \n",
    "#     np_img = np.array(img)\n",
    "#     aug_img = aug(image=np_img)['image']\n",
    "#     return PILImage.create(aug_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "forbidden-punishment",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# # a_list = [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 0.999]\n",
    "# a_list=[1]\n",
    "# # a_list = np.arange(0.5,1.0,0.1)\n",
    "# #[1] #[0,45,90,135]  #[750, 800, 850, 900]# list(np.arange(0, 5, 0.5)) # [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0]\n",
    "# scores_gs = []\n",
    "\n",
    "# for VARIABLE in a_list:\n",
    "#     aug_tfms =  aug_transforms(size=RESOLUTION, pad_mode='reflection', do_flip=True, batch=False, \n",
    "#                                    p_affine=0.7, max_rotate=45, max_warp=0, min_zoom=1.0, max_zoom=2.5, \n",
    "#                                    mult=3,  p_lighting=0.5, max_lighting=0.1, min_scale=0.75) #,xtra_tfms=[sha])\n",
    "\n",
    "#     sat = Saturation(p=0.7, max_lighting=0.2)\n",
    "\n",
    "#     # batch_tfms = [ Normalize.from_stats(*imagenet_stats), sat]\n",
    "#     batch_tfms = [ *aug_tfms, sat, Normalize.from_stats(*imagenet_stats)]#, sha]\n",
    "\n",
    "# #     item_tfms=RandomResizedCrop(RESOLUTION)\n",
    "#     item_tfms=Resize(RESOLUTION, method='bilinear', pad_mode='zeros')\n",
    "# #     item_tfms=RatioResize(RESOLUTION)\n",
    "\n",
    "#     dls = ImageDataLoaders.from_df(sample_df, folder=f'../data/{sub}', seed=42, label_col = 0, fn_col=1, \n",
    "#                                    batch_tfms=batch_tfms, bs=BATCH_SIZE, item_tfms=item_tfms)\n",
    "#     test_dl = dls.test_dl(sample_df)\n",
    "\n",
    "#     preds, something = model.tta(dl=test_dl, n=5, use_max=False, beta=0.18)\n",
    "#     scores_gs.append(accuracy_score(sample_df.iloc[:,0], preds.argmax(dim=-1).numpy()))  # TTA\n",
    "    \n",
    "#     print(f'best SO FAR: {a_list[np.argmax(scores_gs)]}, at {scores_gs[np.argmax(scores_gs)]}')\n",
    "\n",
    "\n",
    "# print(f'best n: {a_list[np.argmax(scores_gs)]}')\n",
    "# print(a_list)\n",
    "# print(scores_gs)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "prepared-phase",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-02-10T09:41:21.127718Z",
     "iopub.status.busy": "2021-02-10T09:41:21.127605Z",
     "iopub.status.idle": "2021-02-10T09:41:21.981508Z",
     "shell.execute_reply": "2021-02-10T09:41:21.981082Z",
     "shell.execute_reply.started": "2021-02-10T09:41:21.127705Z"
    }
   },
   "source": [
    "test_dl.show_batch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "understanding-heating",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "unlimited-ribbon",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "piano-irish",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
